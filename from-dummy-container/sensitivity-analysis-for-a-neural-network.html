<!DOCTYPE html>
<html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<title>Chapter 6 Sensitivity analysis for a neural network | A Machine Learning Compilation</title>
<meta name="author" content="Several authors. Compiled by Alfonso R. Reyes">
<!-- JS --><script src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.6/clipboard.min.js" integrity="sha256-inc5kl9MA1hkeYUt+EC3BhlIgyp/2jDIyBLS6k3UxPI=" crossorigin="anonymous"></script><script src="https://cdn.jsdelivr.net/npm/fuse.js@6.4.2"></script><script src="https://kit.fontawesome.com/6ecbd6c532.js" crossorigin="anonymous"></script><script src="libs/jquery-3.5.1/jquery-3.5.1.min.js"></script><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<link href="libs/bootstrap-4.5.3/bootstrap.min.css" rel="stylesheet">
<script src="libs/bootstrap-4.5.3/bootstrap.bundle.min.js"></script><script src="libs/bs3compat-0.2.2.9000/tabs.js"></script><script src="libs/bs3compat-0.2.2.9000/bs3compat.js"></script><link href="libs/bs4_book-1.0.0/bs4_book.css" rel="stylesheet">
<script src="libs/bs4_book-1.0.0/bs4_book.js"></script><script src="https://cdn.jsdelivr.net/autocomplete.js/0/autocomplete.jquery.min.js"></script><script src="https://cdn.jsdelivr.net/npm/mark.js@8.11.1/dist/mark.min.js"></script><!-- CSS -->
</head>
<body data-spy="scroll" data-target="#toc">

<div class="container-fluid">
<div class="row">
  <header class="col-sm-12 col-lg-3 sidebar sidebar-book"><a class="sr-only sr-only-focusable" href="#content">Skip to main content</a>

    <div class="d-flex align-items-start justify-content-between">
      <h1>
        <a href="index.html" title="">A Machine Learning Compilation</a>
      </h1>
      <button class="btn btn-outline-primary d-lg-none ml-2 mt-1" type="button" data-toggle="collapse" data-target="#main-nav" aria-expanded="true" aria-controls="main-nav"><i class="fas fa-bars"></i><span class="sr-only">Show table of contents</span></button>
    </div>

    <div id="main-nav" class="collapse-lg">
      <form role="search">
        <input id="search" class="form-control" type="search" placeholder="Search" aria-label="Search">
</form>

      <nav aria-label="Table of contents"><h2>Table of contents</h2>
        <ul class="book-toc list-unstyled">
<li><a class="" href="index.html"><span class="header-section-number">1</span> Preface</a></li>
<li class="book-part">The Basics of Machine Learning</li>
<li><a class="" href="introduction-to-pca.html"><span class="header-section-number">2</span> Introduction to PCA</a></li>
<li><a class="" href="comparison-of-two-pca-packages.html"><span class="header-section-number">3</span> Comparison of two PCA packages</a></li>
<li><a class="" href="detailed-study-of-principal-component-analysis.html"><span class="header-section-number">4</span> Detailed study of Principal Component Analysis</a></li>
<li><a class="" href="detection-of-diabetes-using-logistic-regression.html"><span class="header-section-number">5</span> Detection of diabetes using Logistic Regression</a></li>
<li><a class="active" href="sensitivity-analysis-for-a-neural-network.html"><span class="header-section-number">6</span> Sensitivity analysis for a neural network</a></li>
<li><a class="" href="data-visualization-for-ml-models.html"><span class="header-section-number">7</span> Data Visualization for ML models</a></li>
<li class="book-part">Feature Engineering</li>
<li><a class="" href="ten-methods-to-assess-variable-importance.html"><span class="header-section-number">8</span> Ten methods to assess Variable Importance</a></li>
<li><a class="" href="employee-attrition-using-feature-importance.html"><span class="header-section-number">9</span> Employee Attrition using Feature Importance</a></li>
<li class="book-part">Classification</li>
<li><a class="" href="a-gentle-introduction-to-support-vector-machines.html"><span class="header-section-number">10</span> A gentle introduction to Support Vector Machines</a></li>
<li><a class="" href="broad-view-of-svm.html"><span class="header-section-number">11</span> Broad view of SVM</a></li>
<li><a class="" href="feature-selection-to-enhance-cancer-detection.html"><span class="header-section-number">12</span> Feature Selection to enhance cancer detection</a></li>
<li><a class="" href="dealing-with-unbalanced-data.html"><span class="header-section-number">13</span> Dealing with unbalanced data</a></li>
<li><a class="" href="imputting-missing-values-with-random-forest.html"><span class="header-section-number">14</span> Imputting missing values with Random Forest</a></li>
<li><a class="" href="tuning-of-support-vector-machine-prediction.html"><span class="header-section-number">15</span> Tuning of Support Vector Machine prediction</a></li>
<li class="book-part">Classification</li>
<li><a class="" href="introduction-to-algorithms-for-classification.html"><span class="header-section-number">16</span> Introduction to algorithms for Classification</a></li>
<li><a class="" href="comparing-classification-algorithms.html"><span class="header-section-number">17</span> Comparing Classification algorithms</a></li>
<li><a class="" href="who-buys-social-network-ads.html"><span class="header-section-number">18</span> Who buys Social Network ads</a></li>
<li><a class="" href="predicting-ozone-levels.html"><span class="header-section-number">19</span> Predicting Ozone levels</a></li>
<li><a class="" href="building-a-naive-bayes-classifier.html"><span class="header-section-number">20</span> Building a Naive Bayes Classifier</a></li>
<li><a class="" href="linear-and-non-linear-algorithms-for-classification.html"><span class="header-section-number">21</span> Linear and Non-Linear Algorithms for Classification</a></li>
<li><a class="" href="detect-mines-vs-rocks-with-random-forest.html"><span class="header-section-number">22</span> Detect mines vs rocks with Random Forest</a></li>
<li><a class="" href="predicting-the-type-of-glass.html"><span class="header-section-number">23</span> Predicting the type of glass</a></li>
<li><a class="" href="naive-bayes-for-sms-spam.html"><span class="header-section-number">24</span> Naive Bayes for SMS spam</a></li>
<li><a class="" href="vehicles-classiification-with-decision-trees.html"><span class="header-section-number">25</span> Vehicles classiification with Decision Trees</a></li>
<li><a class="" href="applying-naive-bayes-on-the-titanic-case.html"><span class="header-section-number">26</span> Applying Naive-Bayes on the Titanic case</a></li>
<li><a class="" href="classification-on-bad-loans.html"><span class="header-section-number">27</span> Classification on bad loans</a></li>
<li><a class="" href="predicting-flu-outcome-comparing-eight-classification-algorithms.html"><span class="header-section-number">28</span> Predicting Flu outcome comparing eight classification algorithms</a></li>
<li><a class="" href="a-detailed-study-of-bike-sharing-demand.html"><span class="header-section-number">29</span> A detailed study of bike sharing demand</a></li>
<li><a class="" href="prediction-of-arrhythmia-with-deep-neural-nets.html"><span class="header-section-number">30</span> Prediction of arrhythmia with deep neural nets</a></li>
<li class="book-part">Linear Regression</li>
<li><a class="" href="linear-regression-with-islr.html"><span class="header-section-number">31</span> Linear Regression with ISLR</a></li>
<li><a class="" href="evaluation-of-three-linear-regression-models.html"><span class="header-section-number">32</span> Evaluation of three linear regression models</a></li>
<li><a class="" href="comparison-of-six-linear-regression-algorithms.html"><span class="header-section-number">33</span> Comparison of six Linear Regression algorithms</a></li>
<li><a class="" href="comparing-regression-models.html"><span class="header-section-number">34</span> Comparing regression models</a></li>
<li><a class="" href="finding-the-factors-of-happiness.html"><span class="header-section-number">35</span> Finding the factors of happiness</a></li>
<li><a class="" href="regression-with-a-neural-network.html"><span class="header-section-number">36</span> Regression with a neural network</a></li>
<li><a class="" href="comparing-multiple-regression-vs-a-neural-network.html"><span class="header-section-number">37</span> Comparing Multiple Regression vs a Neural Network</a></li>
<li><a class="" href="temperature-modeling-using-nested-dataframes.html"><span class="header-section-number">38</span> Temperature modeling using nested dataframes</a></li>
<li class="book-part">Neural Networks</li>
<li><a class="" href="credit-scoring-with-neuralnet.html"><span class="header-section-number">39</span> Credit Scoring with neuralnet</a></li>
<li><a class="" href="wine-classification-with-neuralnet.html"><span class="header-section-number">40</span> Wine classification with neuralnet</a></li>
<li><a class="" href="predicting-the-rating-of-cereals.html"><span class="header-section-number">41</span> Predicting the rating of cereals</a></li>
<li><a class="" href="fitting-a-linear-model-with-neural-networks.html"><span class="header-section-number">42</span> Fitting a linear model with neural networks</a></li>
<li><a class="" href="visualization-of-neural-networks.html"><span class="header-section-number">43</span> Visualization of neural networks</a></li>
<li><a class="" href="build-a-fully-connected-r-neural-network-from-scratch.html"><span class="header-section-number">44</span> Build a fully connected R neural network from scratch</a></li>
<li><a class="" href="tuning-hyperparameters-in-a-neural-network.html"><span class="header-section-number">45</span> Tuning Hyperparameters in a Neural Network</a></li>
<li><a class="" href="deep-learning-tips-for-classification-and-regression.html"><span class="header-section-number">46</span> Deep Learning tips for Classification and Regression</a></li>
<li class="book-part">Appendix</li>
<li><a class="" href="what-is-dot-hat-in-a-regression-output.html"><span class="header-section-number">A</span> What is dot hat in a regression output</a></li>
<li><a class="" href="q-q-normal-to-compare-data-to-distributions.html"><span class="header-section-number">B</span> Q-Q normal to compare data to distributions</a></li>
<li><a class="" href="qq-and-pp-plots.html"><span class="header-section-number">C</span> QQ and PP Plots</a></li>
<li><a class="" href="visualizing-residuals.html"><span class="header-section-number">D</span> Visualizing residuals</a></li>
</ul>

        <div class="book-extra">
          <p><a id="book-repo" href="https://github.com/f0nzie/machine_learning_compilation">View book source <i class="fab fa-github"></i></a></p>
        </div>
      </nav>
</div>
  </header><main class="col-sm-12 col-md-9 col-lg-7" id="content"><div id="sensitivity-analysis-for-a-neural-network" class="section level1">
<h1>
<span class="header-section-number">6</span> Sensitivity analysis for a neural network<a class="anchor" aria-label="anchor" href="#sensitivity-analysis-for-a-neural-network"><i class="fas fa-link"></i></a>
</h1>
<ul>
<li>Datasets: Simulated data with normal distribution</li>
<li>Algorithms:
<ul>
<li>Neural Networks</li>
</ul>
</li>
</ul>
<div id="introduction-1" class="section level2">
<h2>
<span class="header-section-number">6.1</span> Introduction<a class="anchor" aria-label="anchor" href="#introduction-1"><i class="fas fa-link"></i></a>
</h2>
<p><a href="https://beckmw.wordpress.com/tag/nnet/" class="uri">https://beckmw.wordpress.com/tag/nnet/</a></p>
<p>I’ve made quite a few blog posts about neural networks and some of the diagnostic tools that can be used to ‘demystify’ the information contained in these models. Frankly, I’m kind of sick of writing about neural networks but I wanted to share one last tool I’ve implemented in R. I’m a strong believer that supervised neural networks can be used for much more than prediction, as is the common assumption by most researchers. I hope that my collection of posts, including this one, has shown the versatility of these models to develop inference into causation. To date, I’ve authored posts on visualizing neural networks, animating neural networks, and determining importance of model inputs. This post will describe a function for a sensitivity analysis of a neural network. Specifically, I will describe an approach to evaluate the form of the relationship of a response variable with the explanatory variables used in the model.</p>
<p>The general goal of a sensitivity analysis is similar to evaluating relative importance of explanatory variables, with a few important distinctions. For both analyses, we are interested in the relationships between explanatory and response variables as described by the model in the hope that the neural network has explained some real-world phenomenon. Using Garson’s algorithm,1 we can get an idea of the magnitude and sign of the relationship between variables relative to each other. Conversely, the sensitivity analysis allows us to obtain information about the form of the relationship between variables rather than a categorical description, such as variable x is positively and strongly related to y. For example, how does a response variable change in relation to increasing or decreasing values of a given explanatory variable? Is it a linear response, non-linear, uni-modal, no response, etc.? Furthermore, how does the form of the response change given values of the other explanatory variables in the model? We might expect that the relationship between a response and explanatory variable might differ given the context of the other explanatory variables (i.e., an interaction may be present). The sensitivity analysis can provide this information.</p>
<p>As with most of my posts, I’ve created the sensitivity analysis function using ideas from other people that are much more clever than me. I’ve simply converted these ideas into a useful form in R. Ultimate credit for the sensitivity analysis goes to Sovan Lek (and colleagues), who developed the approach in the mid-1990s. The ‘Lek-profile method’ is described briefly in Lek et al. 19962 and in more detail in Gevrey et al. 2003.3 I’ll provide a brief summary here since the method is pretty simple. In fact, the profile method can be extended to any statistical model and is not specific to neural networks, although it is one of few methods used to evaluate the latter. For any statistical model where multiple response variables are related to multiple explanatory variables, we choose one response and one explanatory variable. We obtain predictions of the response variable across the range of values for the given explanatory variable. All other explanatory variables are held constant at a given set of respective values (e.g., minimum, 20th percentile, maximum). The final product is a set of response curves for one response variable across the range of values for one explanatory variable, while holding all other explanatory variables constant. This is implemented in R by creating a matrix of values for explanatory variables where the number of rows is the number of observations and the number of columns is the number of explanatory variables. All explanatory variables are held at their mean (or other constant value) while the variable of interest is sequenced from its minimum to maximum value across the range of observations. This matrix (actually a data frame) is then used to predict values of the response variable from a fitted model object. This is repeated for different variables.</p>
<p>I’ll illustrate the function using simulated data, as I’ve done in previous posts. The exception here is that I’ll be using two response variables instead of one. The two response variables are linear combinations of eight explanatory variables, with random error components taken from a normal distribution. The relationships between the variables are determined by the arbitrary set of parameters (<code>parms1</code> and <code>parms2</code>). The explanatory variables are partially correlated and taken from a multivariate normal distribution.</p>
<div class="sourceCode" id="cb130"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="kw"><a href="https://rdrr.io/r/base/library.html">require</a></span><span class="op">(</span><span class="va">clusterGeneration</span><span class="op">)</span>
<span class="co">#&gt; Loading required package: clusterGeneration</span>
<span class="co">#&gt; Loading required package: MASS</span>
<span class="kw"><a href="https://rdrr.io/r/base/library.html">require</a></span><span class="op">(</span><span class="va"><a href="http://www.stats.ox.ac.uk/pub/MASS4/">nnet</a></span><span class="op">)</span>
<span class="co">#&gt; Loading required package: nnet</span>
  
<span class="co">#define number of variables and observations</span>
<span class="fu"><a href="https://rdrr.io/r/base/Random.html">set.seed</a></span><span class="op">(</span><span class="fl">2</span><span class="op">)</span>
<span class="va">num.vars</span><span class="op">&lt;-</span><span class="fl">8</span>
<span class="va">num.obs</span><span class="op">&lt;-</span><span class="fl">10000</span>
  
<span class="co">#define correlation matrix for explanatory variables </span>
<span class="co">#define actual parameter values</span>
<span class="va">cov.mat</span><span class="op">&lt;-</span><span class="fu"><a href="https://rdrr.io/pkg/clusterGeneration/man/genPositiveDefMat.html">genPositiveDefMat</a></span><span class="op">(</span><span class="va">num.vars</span>,covMethod<span class="op">=</span><span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="st">"unifcorrmat"</span><span class="op">)</span><span class="op">)</span><span class="op">$</span><span class="va">Sigma</span>
<span class="va">rand.vars</span><span class="op">&lt;-</span><span class="fu">mvrnorm</span><span class="op">(</span><span class="va">num.obs</span>,<span class="fu"><a href="https://rdrr.io/r/base/rep.html">rep</a></span><span class="op">(</span><span class="fl">0</span>,<span class="va">num.vars</span><span class="op">)</span>,Sigma<span class="op">=</span><span class="va">cov.mat</span><span class="op">)</span>
<span class="va">parms1</span><span class="op">&lt;-</span><span class="fu"><a href="https://rdrr.io/r/stats/Uniform.html">runif</a></span><span class="op">(</span><span class="va">num.vars</span>,<span class="op">-</span><span class="fl">10</span>,<span class="fl">10</span><span class="op">)</span>
<span class="va">y1</span><span class="op">&lt;-</span><span class="va">rand.vars</span> <span class="op">%*%</span> <span class="fu"><a href="https://rdrr.io/r/base/matrix.html">matrix</a></span><span class="op">(</span><span class="va">parms1</span><span class="op">)</span> <span class="op">+</span> <span class="fu"><a href="https://rdrr.io/r/stats/Normal.html">rnorm</a></span><span class="op">(</span><span class="va">num.obs</span>,sd<span class="op">=</span><span class="fl">20</span><span class="op">)</span>
<span class="va">parms2</span><span class="op">&lt;-</span><span class="fu"><a href="https://rdrr.io/r/stats/Uniform.html">runif</a></span><span class="op">(</span><span class="va">num.vars</span>,<span class="op">-</span><span class="fl">10</span>,<span class="fl">10</span><span class="op">)</span>
<span class="va">y2</span><span class="op">&lt;-</span><span class="va">rand.vars</span> <span class="op">%*%</span> <span class="fu"><a href="https://rdrr.io/r/base/matrix.html">matrix</a></span><span class="op">(</span><span class="va">parms2</span><span class="op">)</span> <span class="op">+</span> <span class="fu"><a href="https://rdrr.io/r/stats/Normal.html">rnorm</a></span><span class="op">(</span><span class="va">num.obs</span>,sd<span class="op">=</span><span class="fl">20</span><span class="op">)</span>
 
<span class="co">#prep data and create neural network</span>
<span class="va">rand.vars</span><span class="op">&lt;-</span><span class="fu"><a href="https://rdrr.io/r/base/data.frame.html">data.frame</a></span><span class="op">(</span><span class="va">rand.vars</span><span class="op">)</span>
<span class="va">resp</span><span class="op">&lt;-</span><span class="fu"><a href="https://rdrr.io/r/base/apply.html">apply</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/cbind.html">cbind</a></span><span class="op">(</span><span class="va">y1</span>,<span class="va">y2</span><span class="op">)</span>,<span class="fl">2</span>, <span class="kw">function</span><span class="op">(</span><span class="va">y</span><span class="op">)</span> <span class="op">(</span><span class="va">y</span><span class="op">-</span><span class="fu"><a href="https://rdrr.io/r/base/Extremes.html">min</a></span><span class="op">(</span><span class="va">y</span><span class="op">)</span><span class="op">)</span><span class="op">/</span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/Extremes.html">max</a></span><span class="op">(</span><span class="va">y</span><span class="op">)</span><span class="op">-</span><span class="fu"><a href="https://rdrr.io/r/base/Extremes.html">min</a></span><span class="op">(</span><span class="va">y</span><span class="op">)</span><span class="op">)</span><span class="op">)</span>
<span class="va">resp</span><span class="op">&lt;-</span><span class="fu"><a href="https://rdrr.io/r/base/data.frame.html">data.frame</a></span><span class="op">(</span><span class="va">resp</span><span class="op">)</span>
<span class="fu"><a href="https://rdrr.io/r/base/names.html">names</a></span><span class="op">(</span><span class="va">resp</span><span class="op">)</span><span class="op">&lt;-</span><span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="st">'Y1'</span>,<span class="st">'Y2'</span><span class="op">)</span></code></pre></div>
<div class="sourceCode" id="cb131"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">mod1</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/pkg/nnet/man/nnet.html">nnet</a></span><span class="op">(</span><span class="va">rand.vars</span>,<span class="va">resp</span>,size<span class="op">=</span><span class="fl">8</span>,linout<span class="op">=</span><span class="cn">T</span><span class="op">)</span>
<span class="co">#&gt; # weights:  90</span>
<span class="co">#&gt; initial  value 30121.205794 </span>
<span class="co">#&gt; iter  10 value 130.537462</span>
<span class="co">#&gt; iter  20 value 57.187090</span>
<span class="co">#&gt; iter  30 value 47.285919</span>
<span class="co">#&gt; iter  40 value 42.778564</span>
<span class="co">#&gt; iter  50 value 39.837784</span>
<span class="co">#&gt; iter  60 value 36.694632</span>
<span class="co">#&gt; iter  70 value 35.140948</span>
<span class="co">#&gt; iter  80 value 34.268819</span>
<span class="co">#&gt; iter  90 value 33.772282</span>
<span class="co">#&gt; iter 100 value 33.472654</span>
<span class="co">#&gt; final  value 33.472654 </span>
<span class="co">#&gt; stopped after 100 iterations</span></code></pre></div>
<div class="sourceCode" id="cb132"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="co">#import the function from Github</span>
<span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va"><a href="https://devtools.r-lib.org/">devtools</a></span><span class="op">)</span>
<span class="co">#&gt; Loading required package: usethis</span>

<span class="co"># source_url('https://gist.githubusercontent.com/fawda123/7471137/raw/466c1474d0a505ff044412703516c34f1a4684a5/nnet_plot_update.r')</span>
<span class="kw"><a href="https://rdrr.io/r/base/source.html">source</a></span><span class="op">(</span><span class="st">"nnet_plot_update.r"</span><span class="op">)</span>
 
<span class="co">#plot each model</span>
<span class="fu">plot.nnet</span><span class="op">(</span><span class="va">mod1</span><span class="op">)</span>
<span class="co">#&gt; Loading required package: scales</span>
<span class="co">#&gt; Loading required package: reshape</span></code></pre></div>
<div class="inline-figure"><img src="003-meta_905-regression-sensitivity_analysis_files/figure-html/unnamed-chunk-3-1.png" width="70%" style="display: block; margin: auto;"></div>
</div>
<div id="the-lek-profile-function" class="section level2">
<h2>
<span class="header-section-number">6.2</span> The Lek profile function<a class="anchor" aria-label="anchor" href="#the-lek-profile-function"><i class="fas fa-link"></i></a>
</h2>
<p>We’ve created a neural network that hopefully describes the relationship of two response variables with eight explanatory variables. The sensitivity analysis lets us visualize these relationships. The Lek profile function can be used once we have a neural network model in our workspace. The function is imported and used as follows:</p>
<div class="sourceCode" id="cb133"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="co"># source('https://gist.githubusercontent.com/fawda123/6860630/raw/b8bf4a6c88d6b392b1bfa6ef24759ae98f31877c/lek_fun.r')</span>
<span class="kw"><a href="https://rdrr.io/r/base/source.html">source</a></span><span class="op">(</span><span class="st">"lek_fun.r"</span><span class="op">)</span>

<span class="fu">lek.fun</span><span class="op">(</span><span class="va">mod1</span><span class="op">)</span>
<span class="co">#&gt; Loading required package: ggplot2</span></code></pre></div>
<div class="inline-figure"><img src="003-meta_905-regression-sensitivity_analysis_files/figure-html/unnamed-chunk-4-1.png" width="70%" style="display: block; margin: auto;"></div>
<blockquote>
<p>Fig: Sensitivity analysis of the two response variables in the neural network model to individual explanatory variables. Splits represent the quantile values at which the remaining explanatory variables were held constant. The function can be obtained <a href="https://gist.githubusercontent.com/fawda123/6860630/raw/b8bf4a6c88d6b392b1bfa6ef24759ae98f31877c/lek_fun.r">here</a></p>
</blockquote>
<p>By default, the function runs a sensitivity analysis for all variables. This creates a busy plot so we may want to look at specific variables of interest. Maybe we want to evaluate different quantile values as well. These options can be changed using the arguments.</p>
<div class="sourceCode" id="cb134"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="fu">lek.fun</span><span class="op">(</span><span class="va">mod1</span>,var.sens<span class="op">=</span><span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="st">'X2'</span>,<span class="st">'X5'</span><span class="op">)</span>,split.vals<span class="op">=</span><span class="fu"><a href="https://rdrr.io/r/base/seq.html">seq</a></span><span class="op">(</span><span class="fl">0</span>,<span class="fl">1</span>,by<span class="op">=</span><span class="fl">0.05</span><span class="op">)</span><span class="op">)</span></code></pre></div>
<div class="inline-figure"><img src="003-meta_905-regression-sensitivity_analysis_files/figure-html/unnamed-chunk-5-1.png" width="70%" style="display: block; margin: auto;"></div>
<blockquote>
<p>Fig: Sensitivity analysis of the two response variables in relation to explanatory variables X2 and X5 and different quantile values for the remaining variables.</p>
</blockquote>
<p>The function also returns a ggplot2 object that can be further modified. You may prefer a different theme, color, or line type, for example.</p>
<div class="sourceCode" id="cb135"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">p1</span><span class="op">&lt;-</span><span class="fu">lek.fun</span><span class="op">(</span><span class="va">mod1</span><span class="op">)</span>
<span class="fu"><a href="https://rdrr.io/r/base/class.html">class</a></span><span class="op">(</span><span class="va">p1</span><span class="op">)</span>
<span class="co">#&gt; [1] "gg"     "ggplot"</span>
<span class="co"># [1] "gg"     "ggplot"</span>
 
<span class="va">p1</span> <span class="op">+</span> 
   <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/ggtheme.html">theme_bw</a></span><span class="op">(</span><span class="op">)</span> <span class="op">+</span>
   <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/scale_brewer.html">scale_colour_brewer</a></span><span class="op">(</span>palette<span class="op">=</span><span class="st">"PuBu"</span><span class="op">)</span> <span class="op">+</span>
   <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/scale_manual.html">scale_linetype_manual</a></span><span class="op">(</span>values<span class="op">=</span><span class="fu"><a href="https://rdrr.io/r/base/rep.html">rep</a></span><span class="op">(</span><span class="st">'dashed'</span>,<span class="fl">6</span><span class="op">)</span><span class="op">)</span> <span class="op">+</span>
   <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/scale_manual.html">scale_size_manual</a></span><span class="op">(</span>values<span class="op">=</span><span class="fu"><a href="https://rdrr.io/r/base/rep.html">rep</a></span><span class="op">(</span><span class="fl">1</span>,<span class="fl">6</span><span class="op">)</span><span class="op">)</span>
<span class="co">#&gt; Scale for 'linetype' is already present. Adding another scale for 'linetype',</span>
<span class="co">#&gt; which will replace the existing scale.</span>
<span class="co">#&gt; Scale for 'size' is already present. Adding another scale for 'size', which</span>
<span class="co">#&gt; will replace the existing scale.</span></code></pre></div>
<div class="inline-figure"><img src="003-meta_905-regression-sensitivity_analysis_files/figure-html/unnamed-chunk-6-1.png" width="70%" style="display: block; margin: auto;"></div>
</div>
<div id="getting-a-dataframe-from-lek" class="section level2">
<h2>
<span class="header-section-number">6.3</span> Getting a dataframe from <code>lek</code><a class="anchor" aria-label="anchor" href="#getting-a-dataframe-from-lek"><i class="fas fa-link"></i></a>
</h2>
<p>Finally, the actual values from the sensitivity analysis can be returned if you’d prefer that instead. The output is a data frame in long form that was created using melt.list from the reshape package for compatibility with ggplot2. The six columns indicate values for explanatory variables on the x-axes, names of the response variables, predicted values of the response variables, quantiles at which other explanatory variables were held constant, and names of the explanatory variables on the x-axes.</p>
<div class="sourceCode" id="cb136"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="fu"><a href="https://rdrr.io/r/utils/head.html">head</a></span><span class="op">(</span><span class="fu">lek.fun</span><span class="op">(</span><span class="va">mod1</span>,val.out <span class="op">=</span> <span class="cn">TRUE</span><span class="op">)</span><span class="op">)</span>
<span class="co">#&gt;   Explanatory resp.name Response Splits exp.name</span>
<span class="co">#&gt; 1       -9.58        Y1    0.466      0       X1</span>
<span class="co">#&gt; 2       -9.39        Y1    0.466      0       X1</span>
<span class="co">#&gt; 3       -9.19        Y1    0.467      0       X1</span>
<span class="co">#&gt; 4       -9.00        Y1    0.467      0       X1</span>
<span class="co">#&gt; 5       -8.81        Y1    0.468      0       X1</span>
<span class="co">#&gt; 6       -8.62        Y1    0.468      0       X1</span></code></pre></div>
</div>
<div id="the-lek-function-works-with-lm" class="section level2">
<h2>
<span class="header-section-number">6.4</span> The <code>lek</code> function works with <code>lm</code><a class="anchor" aria-label="anchor" href="#the-lek-function-works-with-lm"><i class="fas fa-link"></i></a>
</h2>
<p>I mentioned earlier that the function is not unique to neural networks and can work with other models created in R. I haven’t done an extensive test of the function, but I’m fairly certain that it will work if the model object has a predict method (e.g., predict.lm). Here’s an example using the function to evaluate a multiple linear regression for one of the response variables.</p>
<div class="sourceCode" id="cb137"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">mod2</span> <span class="op">&lt;-</span><span class="fu"><a href="https://rdrr.io/r/stats/lm.html">lm</a></span><span class="op">(</span><span class="va">Y1</span> <span class="op">~</span> <span class="va">.</span>, data <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/cbind.html">cbind</a></span><span class="op">(</span><span class="va">resp</span><span class="op">[</span>,<span class="st">'Y1'</span>, drop <span class="op">=</span> <span class="cn">F</span><span class="op">]</span>, <span class="va">rand.vars</span><span class="op">)</span><span class="op">)</span>
<span class="fu">lek.fun</span><span class="op">(</span><span class="va">mod2</span><span class="op">)</span></code></pre></div>
<div class="inline-figure"><img src="003-meta_905-regression-sensitivity_analysis_files/figure-html/unnamed-chunk-8-1.png" width="70%" style="display: block; margin: auto;"></div>
<p>This function has little relevance for conventional models like linear regression since a wealth of <code>diagnostic</code> tools are already available (e.g., effects plots, add/drop procedures, outlier tests, etc.). The application of the function to neural networks provides insight into the relationships described by the models, insights that to my knowledge, cannot be obtained using current tools in R. This post concludes my contribution of diagnostic tools for neural networks in R and I hope that they have been useful to some of you. I have spent the last year or so working with neural networks and my opinion of their utility is mixed. I see advantages in the use of highly flexible computer-based algorithms, although in most cases similar conclusions can be made using more conventional analyses. I suggest that neural networks only be used <em>if there is an extremely high sample size</em> and other methods have proven inconclusive. Feel free to voice your opinions or suggestions in the comments.</p>
</div>
<div id="lek-function-works-with-rsnns" class="section level2">
<h2>
<span class="header-section-number">6.5</span> <code>lek</code> function works with <code>RSNNS</code><a class="anchor" aria-label="anchor" href="#lek-function-works-with-rsnns"><i class="fas fa-link"></i></a>
</h2>
<div class="sourceCode" id="cb138"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="kw"><a href="https://rdrr.io/r/base/library.html">require</a></span><span class="op">(</span><span class="va">clusterGeneration</span><span class="op">)</span>
<span class="kw"><a href="https://rdrr.io/r/base/library.html">require</a></span><span class="op">(</span><span class="va"><a href="https://github.com/cbergmeir/RSNNS">RSNNS</a></span><span class="op">)</span>
<span class="co">#&gt; Loading required package: RSNNS</span>
<span class="co">#&gt; Loading required package: Rcpp</span>
<span class="kw"><a href="https://rdrr.io/r/base/library.html">require</a></span><span class="op">(</span><span class="va"><a href="https://devtools.r-lib.org/">devtools</a></span><span class="op">)</span>
 
<span class="co">#define number of variables and observations</span>
<span class="fu"><a href="https://rdrr.io/r/base/Random.html">set.seed</a></span><span class="op">(</span><span class="fl">2</span><span class="op">)</span>
<span class="va">num.vars</span><span class="op">&lt;-</span><span class="fl">8</span>
<span class="va">num.obs</span><span class="op">&lt;-</span><span class="fl">10000</span>
 
<span class="co">#define correlation matrix for explanatory variables </span>
<span class="co">#define actual parameter values</span>
<span class="va">cov.mat</span> <span class="op">&lt;-</span><span class="fu"><a href="https://rdrr.io/pkg/clusterGeneration/man/genPositiveDefMat.html">genPositiveDefMat</a></span><span class="op">(</span><span class="va">num.vars</span>,covMethod<span class="op">=</span><span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="st">"unifcorrmat"</span><span class="op">)</span><span class="op">)</span><span class="op">$</span><span class="va">Sigma</span>
<span class="va">rand.vars</span> <span class="op">&lt;-</span><span class="fu">mvrnorm</span><span class="op">(</span><span class="va">num.obs</span>,<span class="fu"><a href="https://rdrr.io/r/base/rep.html">rep</a></span><span class="op">(</span><span class="fl">0</span>,<span class="va">num.vars</span><span class="op">)</span>,Sigma<span class="op">=</span><span class="va">cov.mat</span><span class="op">)</span>
<span class="va">parms1</span> <span class="op">&lt;-</span><span class="fu"><a href="https://rdrr.io/r/stats/Uniform.html">runif</a></span><span class="op">(</span><span class="va">num.vars</span>,<span class="op">-</span><span class="fl">10</span>,<span class="fl">10</span><span class="op">)</span>
<span class="va">y1</span> <span class="op">&lt;-</span><span class="va">rand.vars</span> <span class="op">%*%</span> <span class="fu"><a href="https://rdrr.io/r/base/matrix.html">matrix</a></span><span class="op">(</span><span class="va">parms1</span><span class="op">)</span> <span class="op">+</span> <span class="fu"><a href="https://rdrr.io/r/stats/Normal.html">rnorm</a></span><span class="op">(</span><span class="va">num.obs</span>,sd<span class="op">=</span><span class="fl">20</span><span class="op">)</span>
<span class="va">parms2</span> <span class="op">&lt;-</span><span class="fu"><a href="https://rdrr.io/r/stats/Uniform.html">runif</a></span><span class="op">(</span><span class="va">num.vars</span>,<span class="op">-</span><span class="fl">10</span>,<span class="fl">10</span><span class="op">)</span>
<span class="va">y2</span> <span class="op">&lt;-</span><span class="va">rand.vars</span> <span class="op">%*%</span> <span class="fu"><a href="https://rdrr.io/r/base/matrix.html">matrix</a></span><span class="op">(</span><span class="va">parms2</span><span class="op">)</span> <span class="op">+</span> <span class="fu"><a href="https://rdrr.io/r/stats/Normal.html">rnorm</a></span><span class="op">(</span><span class="va">num.obs</span>,sd<span class="op">=</span><span class="fl">20</span><span class="op">)</span>
 
<span class="co">#prep data and create neural network</span>
<span class="va">rand.vars</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/data.frame.html">data.frame</a></span><span class="op">(</span><span class="va">rand.vars</span><span class="op">)</span>
<span class="va">resp</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/apply.html">apply</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/cbind.html">cbind</a></span><span class="op">(</span><span class="va">y1</span>,<span class="va">y2</span><span class="op">)</span>,<span class="fl">2</span>, <span class="kw">function</span><span class="op">(</span><span class="va">y</span><span class="op">)</span> <span class="op">(</span><span class="va">y</span><span class="op">-</span><span class="fu"><a href="https://rdrr.io/r/base/Extremes.html">min</a></span><span class="op">(</span><span class="va">y</span><span class="op">)</span><span class="op">)</span><span class="op">/</span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/Extremes.html">max</a></span><span class="op">(</span><span class="va">y</span><span class="op">)</span><span class="op">-</span><span class="fu"><a href="https://rdrr.io/r/base/Extremes.html">min</a></span><span class="op">(</span><span class="va">y</span><span class="op">)</span><span class="op">)</span><span class="op">)</span>
<span class="va">resp</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/data.frame.html">data.frame</a></span><span class="op">(</span><span class="va">resp</span><span class="op">)</span>
<span class="fu"><a href="https://rdrr.io/r/base/names.html">names</a></span><span class="op">(</span><span class="va">resp</span><span class="op">)</span><span class="op">&lt;-</span><span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="st">'Y1'</span>,<span class="st">'Y2'</span><span class="op">)</span></code></pre></div>
<div class="sourceCode" id="cb139"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="fu">tibble</span><span class="fu">::</span><span class="fu"><a href="https://tibble.tidyverse.org/reference/as_tibble.html">as_tibble</a></span><span class="op">(</span><span class="va">rand.vars</span><span class="op">)</span>
<span class="co">#&gt; # A tibble: 10,000 x 8</span>
<span class="co">#&gt;        X1     X2     X3     X4     X5    X6    X7     X8</span>
<span class="co">#&gt;     &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt;</span>
<span class="co">#&gt; 1  1.61    2.13   2.13   3.97  -1.34   2.00  3.11 -2.55 </span>
<span class="co">#&gt; 2 -1.25    3.07  -0.325  1.61  -0.484  2.28  2.98 -1.71 </span>
<span class="co">#&gt; 3 -3.17   -1.29  -1.77  -1.66  -0.549 -3.19  1.07  1.81 </span>
<span class="co">#&gt; 4 -2.39    3.28  -3.42  -0.160 -1.52   2.67  7.05 -1.14 </span>
<span class="co">#&gt; 5 -1.55   -0.181 -1.14   2.27  -1.68  -1.67  3.08  0.334</span>
<span class="co">#&gt; 6  0.0690 -1.54  -2.98   2.84   1.42   1.31  1.82  2.07 </span>
<span class="co">#&gt; # … with 9,994 more rows</span></code></pre></div>
<div class="sourceCode" id="cb140"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="fu">tibble</span><span class="fu">::</span><span class="fu"><a href="https://tibble.tidyverse.org/reference/as_tibble.html">as_tibble</a></span><span class="op">(</span><span class="va">resp</span><span class="op">)</span>
<span class="co">#&gt; # A tibble: 10,000 x 2</span>
<span class="co">#&gt;      Y1    Y2</span>
<span class="co">#&gt;   &lt;dbl&gt; &lt;dbl&gt;</span>
<span class="co">#&gt; 1 0.461 0.500</span>
<span class="co">#&gt; 2 0.416 0.509</span>
<span class="co">#&gt; 3 0.534 0.675</span>
<span class="co">#&gt; 4 0.548 0.619</span>
<span class="co">#&gt; 5 0.519 0.659</span>
<span class="co">#&gt; 6 0.389 0.622</span>
<span class="co">#&gt; # … with 9,994 more rows</span></code></pre></div>
<div class="sourceCode" id="cb141"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="co"># create neural network model</span>
<span class="va">mod2</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/pkg/RSNNS/man/mlp.html">mlp</a></span><span class="op">(</span><span class="va">rand.vars</span>, <span class="va">resp</span>, size <span class="op">=</span> <span class="fl">8</span>, linOut <span class="op">=</span> <span class="cn">T</span><span class="op">)</span>
 
<span class="co">#import sensitivity analysis function</span>
<span class="fu"><a href="https://devtools.r-lib.org//reference/source_url.html">source_url</a></span><span class="op">(</span><span class="st">'https://gist.githubusercontent.com/fawda123/6860630/raw/b8bf4a6c88d6b392b1bfa6ef24759ae98f31877c/lek_fun.r'</span><span class="op">)</span>
<span class="co">#&gt; SHA-1 hash of file is 4a2d33b94a08f46a94518207a4ae7cc412845222</span>
 
<span class="co">#sensitivity analsyis, note 'exp.in' argument</span>
<span class="fu">lek.fun</span><span class="op">(</span><span class="va">mod2</span>, exp.in <span class="op">=</span> <span class="va">rand.vars</span><span class="op">)</span></code></pre></div>
<div class="inline-figure"><img src="003-meta_905-regression-sensitivity_analysis_files/figure-html/unnamed-chunk-12-1.png" width="70%" style="display: block; margin: auto;"></div>
</div>
<div id="references" class="section level2">
<h2>
<span class="header-section-number">6.6</span> References<a class="anchor" aria-label="anchor" href="#references"><i class="fas fa-link"></i></a>
</h2>
<p>1 Garson GD. 1991. Interpreting neural network connection weights. Artificial Intelligence Expert. 6:46–51.
2 Lek S, Delacoste M, Baran P, Dimopoulos I, Lauga J, Aulagnier S. 1996. Application of neural networks to modelling nonlinear relationships in Ecology. Ecological Modelling. 90:39-52.
3 Gevrey M, Dimopoulos I, Lek S. 2003. Review and comparison of methods to study the contribution of variables in artificial neural network models. Ecological Modelling. 160:249-264.</p>

</div>
</div>
  <div class="chapter-nav">
<div class="prev"><a href="detection-of-diabetes-using-logistic-regression.html"><span class="header-section-number">5</span> Detection of diabetes using Logistic Regression</a></div>
<div class="next"><a href="data-visualization-for-ml-models.html"><span class="header-section-number">7</span> Data Visualization for ML models</a></div>
</div></main><div class="col-md-3 col-lg-2 d-none d-md-block sidebar sidebar-chapter">
    <nav id="toc" data-toggle="toc" aria-label="On this page"><h2>On this page</h2>
      <ul class="nav navbar-nav">
<li><a class="nav-link" href="#sensitivity-analysis-for-a-neural-network"><span class="header-section-number">6</span> Sensitivity analysis for a neural network</a></li>
<li><a class="nav-link" href="#introduction-1"><span class="header-section-number">6.1</span> Introduction</a></li>
<li><a class="nav-link" href="#the-lek-profile-function"><span class="header-section-number">6.2</span> The Lek profile function</a></li>
<li><a class="nav-link" href="#getting-a-dataframe-from-lek"><span class="header-section-number">6.3</span> Getting a dataframe from lek</a></li>
<li><a class="nav-link" href="#the-lek-function-works-with-lm"><span class="header-section-number">6.4</span> The lek function works with lm</a></li>
<li><a class="nav-link" href="#lek-function-works-with-rsnns"><span class="header-section-number">6.5</span> lek function works with RSNNS</a></li>
<li><a class="nav-link" href="#references"><span class="header-section-number">6.6</span> References</a></li>
</ul>

      <div class="book-extra">
        <ul class="list-unstyled">
<li><a id="book-source" href="https://github.com/f0nzie/machine_learning_compilation/blob/master/003-meta_905-regression-sensitivity_analysis.Rmd">View source <i class="fab fa-github"></i></a></li>
          <li><a id="book-edit" href="https://github.com/f0nzie/machine_learning_compilation/edit/master/003-meta_905-regression-sensitivity_analysis.Rmd">Edit this page <i class="fab fa-github"></i></a></li>
        </ul>
</div>
    </nav>
</div>

</div>
</div> <!-- .container -->

<footer class="bg-primary text-light mt-5"><div class="container"><div class="row">

  <div class="col-12 col-md-6 mt-3">
    <p>"<strong>A Machine Learning Compilation</strong>" was written by Several authors. Compiled by Alfonso R. Reyes. It was last built on 2020-11-19.</p>
  </div>

  <div class="col-12 col-md-6 mt-3">
    <p>This book was built by the <a class="text-light" href="https://bookdown.org">bookdown</a> R package.</p>
  </div>

</div></div>
</footer><!-- dynamically load mathjax for compatibility with self-contained --><script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>
</html>
