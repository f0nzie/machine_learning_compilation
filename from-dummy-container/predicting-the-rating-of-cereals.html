<!DOCTYPE html>
<html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<title>Chapter 41 Predicting the rating of cereals | A Machine Learning Compilation</title>
<meta name="author" content="Several authors. Compiled by Alfonso R. Reyes">
<!-- JS --><script src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.6/clipboard.min.js" integrity="sha256-inc5kl9MA1hkeYUt+EC3BhlIgyp/2jDIyBLS6k3UxPI=" crossorigin="anonymous"></script><script src="https://cdn.jsdelivr.net/npm/fuse.js@6.4.2"></script><script src="https://kit.fontawesome.com/6ecbd6c532.js" crossorigin="anonymous"></script><script src="libs/jquery-3.5.1/jquery-3.5.1.min.js"></script><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<link href="libs/bootstrap-4.5.3/bootstrap.min.css" rel="stylesheet">
<script src="libs/bootstrap-4.5.3/bootstrap.bundle.min.js"></script><script src="libs/bs3compat-0.2.2.9000/tabs.js"></script><script src="libs/bs3compat-0.2.2.9000/bs3compat.js"></script><link href="libs/bs4_book-1.0.0/bs4_book.css" rel="stylesheet">
<script src="libs/bs4_book-1.0.0/bs4_book.js"></script><script src="https://cdn.jsdelivr.net/autocomplete.js/0/autocomplete.jquery.min.js"></script><script src="https://cdn.jsdelivr.net/npm/mark.js@8.11.1/dist/mark.min.js"></script><!-- CSS -->
</head>
<body data-spy="scroll" data-target="#toc">

<div class="container-fluid">
<div class="row">
  <header class="col-sm-12 col-lg-3 sidebar sidebar-book"><a class="sr-only sr-only-focusable" href="#content">Skip to main content</a>

    <div class="d-flex align-items-start justify-content-between">
      <h1>
        <a href="index.html" title="">A Machine Learning Compilation</a>
      </h1>
      <button class="btn btn-outline-primary d-lg-none ml-2 mt-1" type="button" data-toggle="collapse" data-target="#main-nav" aria-expanded="true" aria-controls="main-nav"><i class="fas fa-bars"></i><span class="sr-only">Show table of contents</span></button>
    </div>

    <div id="main-nav" class="collapse-lg">
      <form role="search">
        <input id="search" class="form-control" type="search" placeholder="Search" aria-label="Search">
</form>

      <nav aria-label="Table of contents"><h2>Table of contents</h2>
        <ul class="book-toc list-unstyled">
<li><a class="" href="index.html"><span class="header-section-number">1</span> Preface</a></li>
<li class="book-part">The Basics of Machine Learning</li>
<li><a class="" href="introduction-to-pca.html"><span class="header-section-number">2</span> Introduction to PCA</a></li>
<li><a class="" href="comparison-of-two-pca-packages.html"><span class="header-section-number">3</span> Comparison of two PCA packages</a></li>
<li><a class="" href="detailed-study-of-principal-component-analysis.html"><span class="header-section-number">4</span> Detailed study of Principal Component Analysis</a></li>
<li><a class="" href="detection-of-diabetes-using-logistic-regression.html"><span class="header-section-number">5</span> Detection of diabetes using Logistic Regression</a></li>
<li><a class="" href="sensitivity-analysis-for-a-neural-network.html"><span class="header-section-number">6</span> Sensitivity analysis for a neural network</a></li>
<li><a class="" href="data-visualization-for-ml-models.html"><span class="header-section-number">7</span> Data Visualization for ML models</a></li>
<li class="book-part">Feature Engineering</li>
<li><a class="" href="ten-methods-to-assess-variable-importance.html"><span class="header-section-number">8</span> Ten methods to assess Variable Importance</a></li>
<li><a class="" href="employee-attrition-using-feature-importance.html"><span class="header-section-number">9</span> Employee Attrition using Feature Importance</a></li>
<li class="book-part">Classification</li>
<li><a class="" href="a-gentle-introduction-to-support-vector-machines.html"><span class="header-section-number">10</span> A gentle introduction to Support Vector Machines</a></li>
<li><a class="" href="broad-view-of-svm.html"><span class="header-section-number">11</span> Broad view of SVM</a></li>
<li><a class="" href="feature-selection-to-enhance-cancer-detection.html"><span class="header-section-number">12</span> Feature Selection to enhance cancer detection</a></li>
<li><a class="" href="dealing-with-unbalanced-data.html"><span class="header-section-number">13</span> Dealing with unbalanced data</a></li>
<li><a class="" href="imputting-missing-values-with-random-forest.html"><span class="header-section-number">14</span> Imputting missing values with Random Forest</a></li>
<li><a class="" href="tuning-of-support-vector-machine-prediction.html"><span class="header-section-number">15</span> Tuning of Support Vector Machine prediction</a></li>
<li class="book-part">Classification</li>
<li><a class="" href="introduction-to-algorithms-for-classification.html"><span class="header-section-number">16</span> Introduction to algorithms for Classification</a></li>
<li><a class="" href="comparing-classification-algorithms.html"><span class="header-section-number">17</span> Comparing Classification algorithms</a></li>
<li><a class="" href="who-buys-social-network-ads.html"><span class="header-section-number">18</span> Who buys Social Network ads</a></li>
<li><a class="" href="predicting-ozone-levels.html"><span class="header-section-number">19</span> Predicting Ozone levels</a></li>
<li><a class="" href="building-a-naive-bayes-classifier.html"><span class="header-section-number">20</span> Building a Naive Bayes Classifier</a></li>
<li><a class="" href="linear-and-non-linear-algorithms-for-classification.html"><span class="header-section-number">21</span> Linear and Non-Linear Algorithms for Classification</a></li>
<li><a class="" href="detect-mines-vs-rocks-with-random-forest.html"><span class="header-section-number">22</span> Detect mines vs rocks with Random Forest</a></li>
<li><a class="" href="predicting-the-type-of-glass.html"><span class="header-section-number">23</span> Predicting the type of glass</a></li>
<li><a class="" href="naive-bayes-for-sms-spam.html"><span class="header-section-number">24</span> Naive Bayes for SMS spam</a></li>
<li><a class="" href="vehicles-classiification-with-decision-trees.html"><span class="header-section-number">25</span> Vehicles classiification with Decision Trees</a></li>
<li><a class="" href="applying-naive-bayes-on-the-titanic-case.html"><span class="header-section-number">26</span> Applying Naive-Bayes on the Titanic case</a></li>
<li><a class="" href="classification-on-bad-loans.html"><span class="header-section-number">27</span> Classification on bad loans</a></li>
<li><a class="" href="predicting-flu-outcome-comparing-eight-classification-algorithms.html"><span class="header-section-number">28</span> Predicting Flu outcome comparing eight classification algorithms</a></li>
<li><a class="" href="a-detailed-study-of-bike-sharing-demand.html"><span class="header-section-number">29</span> A detailed study of bike sharing demand</a></li>
<li><a class="" href="prediction-of-arrhythmia-with-deep-neural-nets.html"><span class="header-section-number">30</span> Prediction of arrhythmia with deep neural nets</a></li>
<li class="book-part">Linear Regression</li>
<li><a class="" href="linear-regression-with-islr.html"><span class="header-section-number">31</span> Linear Regression with ISLR</a></li>
<li><a class="" href="evaluation-of-three-linear-regression-models.html"><span class="header-section-number">32</span> Evaluation of three linear regression models</a></li>
<li><a class="" href="comparison-of-six-linear-regression-algorithms.html"><span class="header-section-number">33</span> Comparison of six Linear Regression algorithms</a></li>
<li><a class="" href="comparing-regression-models.html"><span class="header-section-number">34</span> Comparing regression models</a></li>
<li><a class="" href="finding-the-factors-of-happiness.html"><span class="header-section-number">35</span> Finding the factors of happiness</a></li>
<li><a class="" href="regression-with-a-neural-network.html"><span class="header-section-number">36</span> Regression with a neural network</a></li>
<li><a class="" href="comparing-multiple-regression-vs-a-neural-network.html"><span class="header-section-number">37</span> Comparing Multiple Regression vs a Neural Network</a></li>
<li><a class="" href="temperature-modeling-using-nested-dataframes.html"><span class="header-section-number">38</span> Temperature modeling using nested dataframes</a></li>
<li class="book-part">Neural Networks</li>
<li><a class="" href="credit-scoring-with-neuralnet.html"><span class="header-section-number">39</span> Credit Scoring with neuralnet</a></li>
<li><a class="" href="wine-classification-with-neuralnet.html"><span class="header-section-number">40</span> Wine classification with neuralnet</a></li>
<li><a class="active" href="predicting-the-rating-of-cereals.html"><span class="header-section-number">41</span> Predicting the rating of cereals</a></li>
<li><a class="" href="fitting-a-linear-model-with-neural-networks.html"><span class="header-section-number">42</span> Fitting a linear model with neural networks</a></li>
<li><a class="" href="visualization-of-neural-networks.html"><span class="header-section-number">43</span> Visualization of neural networks</a></li>
<li><a class="" href="build-a-fully-connected-r-neural-network-from-scratch.html"><span class="header-section-number">44</span> Build a fully connected R neural network from scratch</a></li>
<li><a class="" href="tuning-hyperparameters-in-a-neural-network.html"><span class="header-section-number">45</span> Tuning Hyperparameters in a Neural Network</a></li>
<li><a class="" href="deep-learning-tips-for-classification-and-regression.html"><span class="header-section-number">46</span> Deep Learning tips for Classification and Regression</a></li>
<li class="book-part">Appendix</li>
<li><a class="" href="what-is-dot-hat-in-a-regression-output.html"><span class="header-section-number">A</span> What is dot hat in a regression output</a></li>
<li><a class="" href="q-q-normal-to-compare-data-to-distributions.html"><span class="header-section-number">B</span> Q-Q normal to compare data to distributions</a></li>
<li><a class="" href="qq-and-pp-plots.html"><span class="header-section-number">C</span> QQ and PP Plots</a></li>
<li><a class="" href="visualizing-residuals.html"><span class="header-section-number">D</span> Visualizing residuals</a></li>
</ul>

        <div class="book-extra">
          <p><a id="book-repo" href="https://github.com/f0nzie/machine_learning_compilation">View book source <i class="fab fa-github"></i></a></p>
        </div>
      </nav>
</div>
  </header><main class="col-sm-12 col-md-9 col-lg-7" id="content"><div id="predicting-the-rating-of-cereals" class="section level1">
<h1>
<span class="header-section-number">41</span> Predicting the rating of cereals<a class="anchor" aria-label="anchor" href="#predicting-the-rating-of-cereals"><i class="fas fa-link"></i></a>
</h1>
<ul>
<li>Datasets: <code>cereals.csv</code>
</li>
<li>Algorithms:
<ul>
<li>Neural Networks</li>
</ul>
</li>
</ul>
<div id="introduction-22" class="section level2">
<h2>
<span class="header-section-number">41.1</span> Introduction<a class="anchor" aria-label="anchor" href="#introduction-22"><i class="fas fa-link"></i></a>
</h2>
<p>Source: <a href="https://www.analyticsvidhya.com/blog/2017/09/creating-visualizing-neural-network-in-r/" class="uri">https://www.analyticsvidhya.com/blog/2017/09/creating-visualizing-neural-network-in-r/</a></p>
<p>Neural network is an information-processing machine and can be viewed as analogous to human nervous system. Just like human nervous system, which is made up of interconnected neurons, a neural network is made up of interconnected information processing units. The information processing units do not work in a linear manner. In fact, neural network draws its strength from parallel processing of information, which allows it to deal with non-linearity. Neural network becomes handy to infer meaning and detect patterns from complex data sets.</p>
<p>Neural network is considered as one of the most useful technique in the world of data analytics. However, it is complex and is often regarded as a black box, i.e. users view the input and output of a neural network but remain clueless about the knowledge generating process. We hope that the article will help readers learn about the internal mechanism of a neural network and get hands-on experience to implement it in R.</p>
</div>
<div id="the-basics-of-neural-networks" class="section level2">
<h2>
<span class="header-section-number">41.2</span> The Basics of Neural Networks<a class="anchor" aria-label="anchor" href="#the-basics-of-neural-networks"><i class="fas fa-link"></i></a>
</h2>
<p>A neural network is a model characterized by an activation function, which is used by interconnected information processing units to transform input into output. A neural network has always been compared to human nervous system. Information in passed through interconnected units analogous to information passage through neurons in humans. The first layer of the neural network receives the raw input, processes it and passes the processed information to the hidden layers. The hidden layer passes the information to the last layer, which produces the output. The advantage of neural network is that it is adaptive in nature. It learns from the information provided, i.e. trains itself from the data, which has a known outcome and optimizes its weights for a better prediction in situations with unknown outcome.</p>
<p>A perceptron, viz. single layer neural network, is the most basic form of a neural network. A perceptron receives multidimensional input and processes it using a weighted summation and an activation function. It is trained using a labeled data and learning algorithm that optimize the weights in the summation processor. A major limitation of perceptron model is its inability to deal with non-linearity. A multilayered neural network overcomes this limitation and helps solve non-linear problems. The input layer connects with hidden layer, which in turn connects to the output layer. The connections are weighted and weights are optimized using a learning rule.</p>
<p>There are many learning rules that are used with neural network:</p>
<ol style="list-style-type: lower-alpha">
<li>least mean square;</li>
<li>gradient descent;</li>
<li>newton’s rule;</li>
<li>conjugate gradient etc.</li>
</ol>
<p>The learning rules can be used in conjunction with backpropgation error method. The learning rule is used to calculate the error at the output unit. This error is backpropagated to all the units such that the error at each unit is proportional to the contribution of that unit towards total error at the output unit. The errors at each unit are then used to optimize the weight at each connection. Figure 1 displays the structure of a simple neural network model for better understanding.</p>
</div>
<div id="fitting-a-neural-network-in-r" class="section level2">
<h2>
<span class="header-section-number">41.3</span> Fitting a Neural Network in R<a class="anchor" aria-label="anchor" href="#fitting-a-neural-network-in-r"><i class="fas fa-link"></i></a>
</h2>
<p>Now we will fit a neural network model in R. In this article, we use a subset of cereal dataset shared by Carnegie Mellon University (CMU). The details of the dataset are on the following link: <a href="http://lib.stat.cmu.edu/DASL/Datafiles/Cereals.html" class="uri">http://lib.stat.cmu.edu/DASL/Datafiles/Cereals.html</a>. The objective is to predict rating of the cereals variables such as calories, proteins, fat etc. The R script is provided side by side and is commented for better understanding of the user. . The data is in .csv format and can be downloaded by clicking: cereals.</p>
<p>Please set working directory in R using setwd( ) function, and keep cereal.csv in the working directory. We use rating as the dependent variable and calories, proteins, fat, sodium and fiber as the independent variables. We divide the data into training and test set. Training set is used to find the relationship between dependent and independent variables while the test set assesses the performance of the model. We use 60% of the dataset as training set. The assignment of the data to training and test set is done using random sampling. We perform random sampling on R using sample ( ) function. We have used set.seed( ) to generate same random sample everytime and maintain consistency. We will use the index variable while fitting neural network to create training and test data sets. The R script is as follows:</p>
<div class="sourceCode" id="cb993"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="co">## Creating index variable </span>

<span class="co"># Read the Data</span>
<span class="va">data</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/utils/read.table.html">read.csv</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/file.path.html">file.path</a></span><span class="op">(</span><span class="va">data_raw_dir</span>, <span class="st">"cereals.csv"</span><span class="op">)</span>, header<span class="op">=</span><span class="cn">T</span><span class="op">)</span>

<span class="co"># Random sampling</span>
<span class="va">samplesize</span> <span class="op">=</span> <span class="fl">0.60</span> <span class="op">*</span> <span class="fu"><a href="https://rdrr.io/r/base/nrow.html">nrow</a></span><span class="op">(</span><span class="va">data</span><span class="op">)</span>
<span class="fu"><a href="https://rdrr.io/r/base/Random.html">set.seed</a></span><span class="op">(</span><span class="fl">80</span><span class="op">)</span>
<span class="va">index</span> <span class="op">=</span> <span class="fu"><a href="https://dplyr.tidyverse.org/reference/sample.html">sample</a></span><span class="op">(</span> <span class="fu"><a href="https://rdrr.io/r/base/seq.html">seq_len</a></span> <span class="op">(</span> <span class="fu"><a href="https://rdrr.io/r/base/nrow.html">nrow</a></span> <span class="op">(</span> <span class="va">data</span> <span class="op">)</span> <span class="op">)</span>, size <span class="op">=</span> <span class="va">samplesize</span> <span class="op">)</span>

<span class="co"># Create training and test set  </span>
<span class="va">datatrain</span> <span class="op">=</span> <span class="va">data</span><span class="op">[</span> <span class="va">index</span>, <span class="op">]</span>
<span class="va">datatest</span> <span class="op">=</span> <span class="va">data</span><span class="op">[</span> <span class="op">-</span><span class="va">index</span>, <span class="op">]</span></code></pre></div>
<div class="sourceCode" id="cb994"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="fu">dplyr</span><span class="fu">::</span><span class="fu"><a href="https://tibble.tidyverse.org/reference/glimpse.html">glimpse</a></span><span class="op">(</span><span class="va">data</span><span class="op">)</span>
<span class="co">#&gt; Rows: 75</span>
<span class="co">#&gt; Columns: 6</span>
<span class="co">#&gt; $ calories &lt;int&gt; 70, 120, 70, 50, 110, 110, 130, 90, 90, 120, 110, 120, 110, …</span>
<span class="co">#&gt; $ protein  &lt;int&gt; 4, 3, 4, 4, 2, 2, 3, 2, 3, 1, 6, 1, 3, 1, 2, 2, 1, 1, 3, 2, …</span>
<span class="co">#&gt; $ fat      &lt;int&gt; 1, 5, 1, 0, 2, 0, 2, 1, 0, 2, 2, 3, 2, 1, 0, 0, 0, 1, 3, 0, …</span>
<span class="co">#&gt; $ sodium   &lt;int&gt; 130, 15, 260, 140, 180, 125, 210, 200, 210, 220, 290, 210, 1…</span>
<span class="co">#&gt; $ fiber    &lt;dbl&gt; 10.0, 2.0, 9.0, 14.0, 1.5, 1.0, 2.0, 4.0, 5.0, 0.0, 2.0, 0.0…</span>
<span class="co">#&gt; $ rating   &lt;dbl&gt; 68.4, 34.0, 59.4, 93.7, 29.5, 33.2, 37.0, 49.1, 53.3, 18.0, …</span></code></pre></div>
<p>Now we fit a neural network on our data. We use <code>neuralnet</code> library for the analysis. The first step is to scale the cereal dataset. The scaling of data is essential because otherwise a variable may have large impact on the prediction variable only because of its scale. Using unscaled may lead to meaningless results. The common techniques to scale data are: min-max normalization, Z-score normalization, median and MAD, and tan-h estimators. The min-max normalization transforms the data into a common range, thus removing the scaling effect from all the variables. Unlike Z-score normalization and median and MAD method, the min-max method retains the original distribution of the variables. We use min-max normalization to scale the data. The R script for scaling the data is as follows.</p>
<div class="sourceCode" id="cb995"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="co">## Scale data for neural network</span>

<span class="va">max</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/pkg/h2o/man/apply.html">apply</a></span><span class="op">(</span><span class="va">data</span> , <span class="fl">2</span> , <span class="va">max</span><span class="op">)</span>
<span class="va">min</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/pkg/h2o/man/apply.html">apply</a></span><span class="op">(</span><span class="va">data</span>, <span class="fl">2</span> , <span class="va">min</span><span class="op">)</span>
<span class="va">scaled</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/as.data.frame.html">as.data.frame</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/pkg/h2o/man/scale.html">scale</a></span><span class="op">(</span><span class="va">data</span>, center <span class="op">=</span> <span class="va">min</span>, scale <span class="op">=</span> <span class="va">max</span> <span class="op">-</span> <span class="va">min</span><span class="op">)</span><span class="op">)</span></code></pre></div>
<div class="sourceCode" id="cb996"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="co">## Fit neural network </span>

<span class="co"># install library</span>
<span class="co"># install.packages("neuralnet ")</span>

<span class="co"># load library</span>
<span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va"><a href="https://github.com/bips-hb/neuralnet">neuralnet</a></span><span class="op">)</span>

<span class="co"># creating training and test set</span>
<span class="va">trainNN</span> <span class="op">=</span> <span class="va">scaled</span><span class="op">[</span><span class="va">index</span> , <span class="op">]</span>
<span class="va">testNN</span> <span class="op">=</span> <span class="va">scaled</span><span class="op">[</span><span class="op">-</span><span class="va">index</span> , <span class="op">]</span>

<span class="co"># fit neural network</span>
<span class="fu"><a href="https://rdrr.io/r/base/Random.html">set.seed</a></span><span class="op">(</span><span class="fl">2</span><span class="op">)</span>
<span class="va">NN</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/pkg/neuralnet/man/neuralnet.html">neuralnet</a></span><span class="op">(</span><span class="va">rating</span> <span class="op">~</span> <span class="va">calories</span> <span class="op">+</span> <span class="va">protein</span> <span class="op">+</span> <span class="va">fat</span> <span class="op">+</span> <span class="va">sodium</span> <span class="op">+</span> <span class="va">fiber</span>, 
               <span class="va">trainNN</span>, hidden <span class="op">=</span> <span class="fl">3</span> , linear.output <span class="op">=</span> <span class="cn">T</span> <span class="op">)</span>

<span class="co"># plot neural network</span>
<span class="fu"><a href="https://rdrr.io/r/graphics/plot.html">plot</a></span><span class="op">(</span><span class="va">NN</span><span class="op">)</span></code></pre></div>
<div class="sourceCode" id="cb997"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="co">## Prediction using neural network</span>

<span class="va">predict_testNN</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/pkg/neuralnet/man/compute.html">compute</a></span><span class="op">(</span><span class="va">NN</span>, <span class="va">testNN</span><span class="op">[</span>,<span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">1</span><span class="op">:</span><span class="fl">5</span><span class="op">)</span><span class="op">]</span><span class="op">)</span>
<span class="va">predict_testNN</span> <span class="op">=</span> <span class="op">(</span><span class="va">predict_testNN</span><span class="op">$</span><span class="va">net.result</span> <span class="op">*</span> <span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/Extremes.html">max</a></span><span class="op">(</span><span class="va">data</span><span class="op">$</span><span class="va">rating</span><span class="op">)</span> <span class="op">-</span> <span class="fu"><a href="https://rdrr.io/r/base/Extremes.html">min</a></span><span class="op">(</span><span class="va">data</span><span class="op">$</span><span class="va">rating</span><span class="op">)</span><span class="op">)</span><span class="op">)</span> <span class="op">+</span> <span class="fu"><a href="https://rdrr.io/r/base/Extremes.html">min</a></span><span class="op">(</span><span class="va">data</span><span class="op">$</span><span class="va">rating</span><span class="op">)</span>

<span class="fu"><a href="https://rdrr.io/r/graphics/plot.html">plot</a></span><span class="op">(</span><span class="va">datatest</span><span class="op">$</span><span class="va">rating</span>, <span class="va">predict_testNN</span>, col<span class="op">=</span><span class="st">'blue'</span>, pch<span class="op">=</span><span class="fl">16</span>, ylab <span class="op">=</span> <span class="st">"predicted rating NN"</span>, xlab <span class="op">=</span> <span class="st">"real rating"</span><span class="op">)</span>

<span class="fu"><a href="https://rdrr.io/r/graphics/abline.html">abline</a></span><span class="op">(</span><span class="fl">0</span>,<span class="fl">1</span><span class="op">)</span>

<span class="co"># Calculate Root Mean Square Error (RMSE)</span>
<span class="va">RMSE.NN</span> <span class="op">=</span> <span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/sum.html">sum</a></span><span class="op">(</span><span class="op">(</span><span class="va">datatest</span><span class="op">$</span><span class="va">rating</span> <span class="op">-</span> <span class="va">predict_testNN</span><span class="op">)</span><span class="op">^</span><span class="fl">2</span><span class="op">)</span> <span class="op">/</span> <span class="fu"><a href="https://rdrr.io/r/base/nrow.html">nrow</a></span><span class="op">(</span><span class="va">datatest</span><span class="op">)</span><span class="op">)</span> <span class="op">^</span> <span class="fl">0.5</span></code></pre></div>
<div class="inline-figure"><img src="601-nn-regression_144-nn_cereals_neuralnet_files/figure-html/predict_nn-1.png" width="70%" style="display: block; margin: auto;"></div>
<div class="sourceCode" id="cb998"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="co">## Cross validation of neural network model</span>

<span class="co"># install relevant libraries</span>
<span class="co"># install.packages("boot")</span>
<span class="co"># install.packages("plyr")</span>

<span class="co"># Load libraries</span>
<span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va">boot</span><span class="op">)</span>
<span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va"><a href="http://had.co.nz/plyr">plyr</a></span><span class="op">)</span>

<span class="co"># Initialize variables</span>
<span class="fu"><a href="https://rdrr.io/r/base/Random.html">set.seed</a></span><span class="op">(</span><span class="fl">50</span><span class="op">)</span>
<span class="va">k</span> <span class="op">=</span> <span class="fl">100</span>
<span class="va">RMSE.NN</span> <span class="op">=</span> <span class="cn">NULL</span>

<span class="va">List</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/list.html">list</a></span><span class="op">(</span> <span class="op">)</span>

<span class="co"># Fit neural network model within nested for loop</span>
<span class="kw">for</span><span class="op">(</span><span class="va">j</span> <span class="kw">in</span> <span class="fl">10</span><span class="op">:</span><span class="fl">65</span><span class="op">)</span><span class="op">{</span>
    <span class="kw">for</span> <span class="op">(</span><span class="va">i</span> <span class="kw">in</span> <span class="fl">1</span><span class="op">:</span><span class="va">k</span><span class="op">)</span> <span class="op">{</span>
        <span class="va">index</span> <span class="op">=</span> <span class="fu"><a href="https://dplyr.tidyverse.org/reference/sample.html">sample</a></span><span class="op">(</span><span class="fl">1</span><span class="op">:</span><span class="fu"><a href="https://rdrr.io/r/base/nrow.html">nrow</a></span><span class="op">(</span><span class="va">data</span><span class="op">)</span>,<span class="va">j</span> <span class="op">)</span>

        <span class="va">trainNN</span> <span class="op">=</span> <span class="va">scaled</span><span class="op">[</span><span class="va">index</span>,<span class="op">]</span>
        <span class="va">testNN</span> <span class="op">=</span> <span class="va">scaled</span><span class="op">[</span><span class="op">-</span><span class="va">index</span>,<span class="op">]</span>
        <span class="va">datatest</span> <span class="op">=</span> <span class="va">data</span><span class="op">[</span><span class="op">-</span><span class="va">index</span>,<span class="op">]</span>

        <span class="va">NN</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/pkg/neuralnet/man/neuralnet.html">neuralnet</a></span><span class="op">(</span><span class="va">rating</span> <span class="op">~</span> <span class="va">calories</span> <span class="op">+</span> <span class="va">protein</span> <span class="op">+</span> <span class="va">fat</span> <span class="op">+</span> <span class="va">sodium</span> <span class="op">+</span> <span class="va">fiber</span>, <span class="va">trainNN</span>, hidden <span class="op">=</span> <span class="fl">3</span>, linear.output<span class="op">=</span> <span class="cn">T</span><span class="op">)</span>
        <span class="va">predict_testNN</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/pkg/neuralnet/man/compute.html">compute</a></span><span class="op">(</span><span class="va">NN</span>,<span class="va">testNN</span><span class="op">[</span>,<span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">1</span><span class="op">:</span><span class="fl">5</span><span class="op">)</span><span class="op">]</span><span class="op">)</span>
        <span class="va">predict_testNN</span> <span class="op">=</span> <span class="op">(</span><span class="va">predict_testNN</span><span class="op">$</span><span class="va">net.result</span><span class="op">*</span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/Extremes.html">max</a></span><span class="op">(</span><span class="va">data</span><span class="op">$</span><span class="va">rating</span><span class="op">)</span><span class="op">-</span><span class="fu"><a href="https://rdrr.io/r/base/Extremes.html">min</a></span><span class="op">(</span><span class="va">data</span><span class="op">$</span><span class="va">rating</span><span class="op">)</span><span class="op">)</span><span class="op">)</span><span class="op">+</span><span class="fu"><a href="https://rdrr.io/r/base/Extremes.html">min</a></span><span class="op">(</span><span class="va">data</span><span class="op">$</span><span class="va">rating</span><span class="op">)</span>

        <span class="va">RMSE.NN</span> <span class="op">[</span><span class="va">i</span><span class="op">]</span><span class="op">&lt;-</span> <span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/sum.html">sum</a></span><span class="op">(</span><span class="op">(</span><span class="va">datatest</span><span class="op">$</span><span class="va">rating</span> <span class="op">-</span> <span class="va">predict_testNN</span><span class="op">)</span><span class="op">^</span><span class="fl">2</span><span class="op">)</span><span class="op">/</span><span class="fu"><a href="https://rdrr.io/r/base/nrow.html">nrow</a></span><span class="op">(</span><span class="va">datatest</span><span class="op">)</span><span class="op">)</span><span class="op">^</span><span class="fl">0.5</span>
    <span class="op">}</span>
    <span class="va">List</span><span class="op">[[</span><span class="va">j</span><span class="op">]</span><span class="op">]</span> <span class="op">=</span> <span class="va">RMSE.NN</span>
<span class="op">}</span>

<span class="va">Matrix.RMSE</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/do.call.html">do.call</a></span><span class="op">(</span><span class="va">cbind</span>, <span class="va">List</span><span class="op">)</span></code></pre></div>
<div class="sourceCode" id="cb999"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="co">## Prepare boxplot</span>
<span class="fu"><a href="https://rdrr.io/r/graphics/boxplot.html">boxplot</a></span><span class="op">(</span><span class="va">Matrix.RMSE</span><span class="op">[</span>,<span class="fl">56</span><span class="op">]</span>, ylab <span class="op">=</span> <span class="st">"RMSE"</span>, main <span class="op">=</span> <span class="st">"RMSE BoxPlot (length of traning set = 65)"</span><span class="op">)</span></code></pre></div>
<div class="inline-figure"><img src="601-nn-regression_144-nn_cereals_neuralnet_files/figure-html/boxplot-1.png" width="70%" style="display: block; margin: auto;"></div>

<div class="sourceCode" id="cb1000"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="co">## Variation of median RMSE </span>
<span class="co"># install.packages("matrixStats")</span>
<span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va"><a href="https://github.com/HenrikBengtsson/matrixStats">matrixStats</a></span><span class="op">)</span>
<span class="co">#&gt; </span>
<span class="co">#&gt; Attaching package: 'matrixStats'</span>
<span class="co">#&gt; The following object is masked from 'package:plyr':</span>
<span class="co">#&gt; </span>
<span class="co">#&gt;     count</span>

<span class="va">med</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/pkg/matrixStats/man/rowMedians.html">colMedians</a></span><span class="op">(</span><span class="va">Matrix.RMSE</span><span class="op">)</span>

<span class="va">X</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/seq.html">seq</a></span><span class="op">(</span><span class="fl">10</span>,<span class="fl">65</span><span class="op">)</span>

<span class="fu"><a href="https://rdrr.io/r/graphics/plot.html">plot</a></span> <span class="op">(</span><span class="va">med</span><span class="op">~</span><span class="va">X</span>, type <span class="op">=</span> <span class="st">"l"</span>, xlab <span class="op">=</span> <span class="st">"length of training set"</span>, ylab <span class="op">=</span> <span class="st">"median RMSE"</span>, main <span class="op">=</span> <span class="st">"Variation of RMSE with length of training set"</span><span class="op">)</span></code></pre></div>
<div class="figure" style="text-align: center">
<span id="fig:var-rmse"></span>
<img src="601-nn-regression_144-nn_cereals_neuralnet_files/figure-html/var-rmse-1.png" alt="Variation of RMSE" width="70%"><p class="caption">
Figure 41.1: Variation of RMSE
</p>
</div>
<p>Figure <a href="predicting-the-rating-of-cereals.html#fig:var-rmse">41.1</a>) shows that the median RMSE of our model decreases as the length of the training the set. This is an important result. The reader must remember that the model accuracy is dependent on the length of training set. The performance of neural network model is sensitive to training-test split.</p>
</div>
<div id="end-notes-1" class="section level2">
<h2>
<span class="header-section-number">41.4</span> End Notes<a class="anchor" aria-label="anchor" href="#end-notes-1"><i class="fas fa-link"></i></a>
</h2>
<p>The article discusses the theoretical aspects of a neural network, its implementation in R and post training evaluation. A Neural network is inspired from biological nervous system. Similar to nervous system the information is passed through layers of processors. The significance of variables is represented by weights of each connection. The article provides basic understanding of back propagation algorithm, which is used to assign these weights. In this article we also implement neural network on R. We use a publicly available dataset shared by CMU. The aim is to predict the rating of cereals using information such as calories, fat, protein etc. After constructing the neural network we evaluate the model for accuracy and robustness. We compute RMSE and perform cross-validation analysis. In cross validation, we check the variation in model accuracy as the length of training set is changed. We consider training sets with length 10 to 65. For each length a 100 samples are random picked and median RMSE is calculated. We show that model accuracy increases when training set is large. Before using the model for prediction, it is important to check the robustness of performance through cross validation.</p>
<p>The article provides a quick review neural network and is a useful reference for data enthusiasts. We have provided commented R code throughout the article to help readers with hands on experience of using neural networks.</p>

</div>
</div>
  <div class="chapter-nav">
<div class="prev"><a href="wine-classification-with-neuralnet.html"><span class="header-section-number">40</span> Wine classification with neuralnet</a></div>
<div class="next"><a href="fitting-a-linear-model-with-neural-networks.html"><span class="header-section-number">42</span> Fitting a linear model with neural networks</a></div>
</div></main><div class="col-md-3 col-lg-2 d-none d-md-block sidebar sidebar-chapter">
    <nav id="toc" data-toggle="toc" aria-label="On this page"><h2>On this page</h2>
      <ul class="nav navbar-nav">
<li><a class="nav-link" href="#predicting-the-rating-of-cereals"><span class="header-section-number">41</span> Predicting the rating of cereals</a></li>
<li><a class="nav-link" href="#introduction-22"><span class="header-section-number">41.1</span> Introduction</a></li>
<li><a class="nav-link" href="#the-basics-of-neural-networks"><span class="header-section-number">41.2</span> The Basics of Neural Networks</a></li>
<li><a class="nav-link" href="#fitting-a-neural-network-in-r"><span class="header-section-number">41.3</span> Fitting a Neural Network in R</a></li>
<li><a class="nav-link" href="#end-notes-1"><span class="header-section-number">41.4</span> End Notes</a></li>
</ul>

      <div class="book-extra">
        <ul class="list-unstyled">
<li><a id="book-source" href="https://github.com/f0nzie/machine_learning_compilation/blob/master/601-nn-regression_144-nn_cereals_neuralnet.Rmd">View source <i class="fab fa-github"></i></a></li>
          <li><a id="book-edit" href="https://github.com/f0nzie/machine_learning_compilation/edit/master/601-nn-regression_144-nn_cereals_neuralnet.Rmd">Edit this page <i class="fab fa-github"></i></a></li>
        </ul>
</div>
    </nav>
</div>

</div>
</div> <!-- .container -->

<footer class="bg-primary text-light mt-5"><div class="container"><div class="row">

  <div class="col-12 col-md-6 mt-3">
    <p>"<strong>A Machine Learning Compilation</strong>" was written by Several authors. Compiled by Alfonso R. Reyes. It was last built on 2020-11-20.</p>
  </div>

  <div class="col-12 col-md-6 mt-3">
    <p>This book was built by the <a class="text-light" href="https://bookdown.org">bookdown</a> R package.</p>
  </div>

</div></div>
</footer><!-- dynamically load mathjax for compatibility with self-contained --><script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>
</html>
