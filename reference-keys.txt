tab:unnamed-chunk-1
fig:unnamed-chunk-5
fig:var-rmse
preface
introduction-to-pca
underlying-principal-components
compute-eigenvectors-and-eigenvalues
comparison-of-two-pca-packages
prcomp-vs-princomp
general-methods-for-principal-component-analysis
prcomp-and-princomp-functions
loading-factoextra
loading-the-decathlon-dataset
compute-pca-in-r-using-prcomp
plots-quality-and-contribution
access-to-the-pca-results
predict-using-pca
supplementary-variables
qualitative-categorical-variables
quantitative-variables
theory-behind-pca-results
pca-results-for-variables
pca-results-for-individuals
detailed-study-of-principal-component-analysis
data-standardization
eigenvalues-variances
graph-of-variables
correlation-circle
quality-of-representation
contributions-of-variables-to-pcs
color-by-a-custom-continuous-variable
color-by-groups
dimension-description
graph-of-individuals
plots-quality-and-contribution-1
color-by-a-custom-continuous-variable-1
color-by-groups-1
graph-customization
dimensions
size-and-shape-of-plot-elements
ellipses
group-mean-points
axis-lines
graphical-parameters
biplot
supplementary-elements
quantitative-variables-1
individuals
qualitative-variables
filtering-results
exporting-results
export-results-to-txtcsv-files
summary
detection-of-diabetes-using-logistic-regression
introduction
exploring-the-data
logistic-regression-with-r
a-second-model
classification-rate-and-confusion-matrix
plots-and-decision-boundaries
sensitivity-analysis-for-a-neural-network
introduction-1
the-lek-profile-function
getting-a-dataframe-from-lek
the-lek-function-works-with-lm
lek-function-works-with-rsnns
references
data-visualization-for-ml-models
introduction-2
show-several-fits-at-once-with-a-legend
look-inside-model-objects
get-model-based-graphics-right
present-your-findings-in-substantive-terms
show-your-degree-of-confidence
show-your-data-when-you-can
generate-predictions-to-graph
tidy-model-objects-with-broom
get-component-level-statistics-with-tidy
get-observation-level-statistics-with-augment
get-model-level-statistics-with-glance
grouped-analysis-and-list-columns
plot-marginal-effects
plots-from-complex-surveys
where-to-go-next
default-plots-for-models
tools-in-development
extensions-to-ggplot
ten-methods-to-assess-variable-importance
boruta
variable-importance
rpart
regularized-random-forest-rrf
lasso-regression
step-wise-forward-and-backward-selection
relative-importance-from-linear-regression
recursive-feature-elimination-rfe
genetic-algorithm
simulated-annealing
information-value-and-weights-of-evidence
dalex-package
conclusion
employee-attrition-using-feature-importance
introduction-3
employee-attrition-a-major-problem
employee-attrition-machine-learning-analysis
where-we-got-the-data
automated-machine-learning-what-we-did-with-the-data
load-packages
load-data
modeling-employee-attrition
machine-learning-with-h2o
model
predict
performance
the-lime-package
set-up
feature-importance-visualization
what-features-are-linked-to-employee-attrition
training
overtime
job-role
conclusions
a-gentle-introduction-to-support-vector-machines
introduction-4
the-rationale
the-kernel-trick
support-vector-machines-in-r
svm-on-the-iris-dataset
training-and-test-datasets
building-the-svm-model
support-vectors
predictions-on-training-model
predictions-on-test-model
confusion-matrix-and-accuracy
svm-with-radial-basis-function-kernel.-linear
training-and-test-sets
predictions-on-the-training-model
predictions-on-the-test-model
svm-with-radial-basis-function-kernel.-non-linear
predictions-on-training-model-1
predictions-on-test-model-1
tuning-of-parameters
prediction-on-training-model-with-new-parameters
prediction-on-test-model-with-new-parameters
wrapping-up
broad-view-of-svm
introduction-5
maximal-margin-classifier
support-vector-classifiers
support-vector-machines
svms-for-multiple-classes
application
feature-selection-to-enhance-cancer-detection
read-and-process-the-data
missing-data
principal-component-analysis-pca
theme
pca-function
density-plots-vs-class
feature-importance
feature-selection
correlation
recursive-feature-elimination-rfe-1
genetic-algorithm-ga
model-comparison
using-all-features
compare-selection-methods
correlation-1
recursive-feature-elimination
ga
create-comparison-tables
notes
dealing-with-unbalanced-data
breast-cancer-dataset
introduction-6
read-and-process-the-data-1
unbalanced-data
why-is-unbalanced-data-a-problem-in-machine-learning
how-to-balance-data-for-modeling
modeling-the-original-unbalanced-data
under-sampling
oversampling
rose
smote
predictions
final-notes
imputting-missing-values-with-random-forest
flu-prediction.-fluh7n9_china_2013-dataset
the-data
pre-processing
features
imputing-missing-values
generate-a-dataframe-of-five-imputting-strategies
plot-effect-of-imputting-on-features
test-train-and-validation-data-sets
machine-learning-algorithms
random-forest
add-model-and-prediction-to-nested-dataframe-and-calculate
add-model-list-column
add-prediction-and-confusion-matrix-list-columns
comparing-accuracy-of-models
tuning-of-support-vector-machine-prediction
support-vector-machines-in-r-1
svm-on-iris-dataset
training-and-test-datasets-1
build-the-svm-model
support-vectors-1
predictions-on-training-model-2
predictions-on-test-model-2
confusion-matrix-and-accuracy-1
svm-with-radial-basis-function-kernel.-linear-1
training-and-test-sets-1
predictions-on-training-model-3
predictions-on-test-model-3
svm-with-radial-basis-function-kernel.-non-linear-1
predictions-on-training-model-4
predictions-on-test-model-4
tuning-of-parameters-1
prediction-on-training-model-with-new-parameters-1
prediction-on-test-model-with-new-parameters-1
wrapping-up-1
introduction-to-algorithms-for-classification
comparison-of-cart-lda-svm-knn-rf
introduction-7
workflow
train-the-models-using-cross-validation
compare-models
plot-comparison
comparing-classification-algorithms
introduction-8
workflow-1
peek-at-the-dataset
levels-of-the-class
class-distribution
visualize-the-dataset
evaluate-algorithms
split-and-metrics
build-models
compare
make-predictions
who-buys-social-network-ads
classification-with-svm
introduction-9
data-operations
load-libraries
importing-the-dataset
encoding-the-target-feature-as-factor
training-and-test-datasets-2
feature-scaling
fitting-svm-to-the-training-set
predicting-the-on-the-test-dataset
confusion-matrix
end
plotting-the-training-dataset
plotting-the-test-dataset
predicting-ozone-levels
building-a-naive-bayes-classifier
building-a-naive-bayes-classifier-in-r
linear-and-non-linear-algorithms-for-classification
introduction-10
workflow-2
inspect-the-dataset
clean-up
analyze-the-class-variable
remove-nas
unimodal-visualization
multimodal-visualization
algorithms-evaluation
data-transform
tuning-svm
tuning-knn
ensemble
finalize-model
prepare-the-validation-set
detect-mines-vs-rocks-with-random-forest
introduction-11
load-libraries-1
explore-data
apply-tuning-parameters-for-final-model
save-model
use-the-saved-model
make-prediction-with-new-data
predicting-the-type-of-glass
comparison-test-sets
comparison-with-resamples
naive-bayes-for-sms-spam
convert-type-to-a-factor
some-conversion
convert-to-document-term-matrix-dtm
split-in-training-and-test-datasets
separate-the-labels
plot-wordcloud
limit-frequent-words
get-only-frequent-words
function-to-change-value-to-yesno
improve-model-performance
vehicles-classiification-with-decision-trees
load-packages-1
prepare-data
estimate-the-decision-tree
assess-model
make-predictions-1
applying-naive-bayes-on-the-titanic-case
can-we-do-any-better
classification-on-bad-loans
comparison-of-glm-rf-gbm-dl-nb
introduction-12
install-and-download-h2o
load-the-dataset
feature-engineering
partition-the-data
identify-response-and-predictor-variables
algorithms
glm
random-forest-1
cross-validate-performance
gradient-boosting-machine-gbm
deep-learning
train-a-default-dl
train-a-dl-with-new-architecture-and-more-epochs.
train-a-dl-with-early-stopping
scoring-history
naive-bayes-model
train-a-nb-model-with-laplace-smoothing
predicting-flu-outcome-comparing-eight-classification-algorithms
introduction-13
algorithms-1
workflow-3
can-we-predict-flu-outcome-with-machine-learning-in-r
the-data-1
features-1
imputing-missing-values-1
test-train-and-validation-data-sets-1
decision-trees
feature-importance-1
feature-plot
plot-distribution-of-features-in-each-dataset
plot-3-features-vs-outcome-all-datasets
comparing-machine-learning-algorithms
random-forest-2
glm-net
k-nearest-neighbors
penalized-discriminant-analysis
stabilized-linear-discriminant-analysis
nearest-shrunken-centroids
single-c5.0-tree
partial-least-squares
comparing-accuracy-of-models-1
summary-accuracy-and-kappa
combined-results-of-predicting-validation-test-samples
predicting-unknown-outcomes
final-results
predicted-outcome
conclusions-1
a-detailed-study-of-bike-sharing-demand
hypothesis-generation
understanding-the-data-set
independent-variables
dependent-variables
importing-the-dataset-and-data-exploration
histograms
density-plots
boxplots
unique-values-of-discrete-variables
inferences
hypothesis-testing-using-multivariate-analysis
hourly-trend
boxplot-count-vs-hour-in-training-set
boxplot-hourly-casual-vs-registered-users-in-the-training-set
outliers-in-the-training-set
daily-trend
boxplot-daily-trend-casual-vs-registered-users-training-set
rain
boxplot-of-rain-effect-on-bike-riding-training-set
temperature
boxplot-of-temperature-effect-training-set
correlation-2
activity-by-year
year-extraction
trend-by-year-training-set
trend-by-windspeed-training-set
trend-by-humidity-training-set
feature-engineering-1
prepare-data-1
build-hour-bins
temperature-bins
assign-temperature-ranges-accoding-to-trees
year-bins-by-quarter
day-type
temperatures
imputting-missing-data-to-wind-speed
weekend-variable
model-building
convert-variables-to-factors
log-transform
plot-by-weather-by-season
predicting-for-registered-and-casual-users-test-dataset
preparing-and-exporting-results
end-notes
prediction-of-arrhythmia-with-deep-neural-nets
introduction-14
deep-learning-with-neural-networks
h2o
preparing-the-r-session
arrhythmia-data
converting-the-dataframe-to-a-h2o-object
training-test-and-validation-data
modeling
model-performance
test-data
final-conclusions-how-useful-is-the-model
linear-regression-with-islr
evaluation-of-three-linear-regression-models
introduction-15
explore-the-data
create-training-and-test-sets
predict-with-simple-linear-regression
predict-with-multiple-regression
predict-with-neural-network-regression
evaluate-all-the-regression-models
comparison-of-six-linear-regression-algorithms
introduction-16
workflow-4
preparing-the-data
variables-correlation
a-look-at-the-variables
evaluation-of-algorithms
feature-selection-1
evaluate-algorithms-box-cox-transform
tune-svm
ensembling
finalize-the-model
comparing-regression-models
introduction-17
split-the-data-into-test-and-training-sets
predict-with-simple-linear-regression-1
predict-with-multiple-linear-regression
predict-with-neural-network-regression-1
evaluate-the-regression-models
finding-the-factors-of-happiness
introduction-18
a-quick-exploration-of-the-data
linear-regression-with-r
regression-summary
regression-analysis
residual-analysis
analysis-of-colinearity
what-drives-happiness
regression-with-a-neural-network
neural-network
linear-regression
comparing-multiple-regression-vs-a-neural-network
introduction-19
multiple-regression
neural-network-1
temperature-modeling-using-nested-dataframes
introduction-20
packages-to-run-this-presentation
motivation
prepare-the-data
lets-get-the-data-into-shape
is-temperature_wide-tidy
tidy-data
lets-get-this-into-a-tidy-form
now-its-easier-to-visualize
calculate-delta-time-delta-t-and-delta-temperature-delta-t
lets-have-a-look
define-the-models
newtonian-cooling
semi-infinite-solid
semi-infinite-solid-with-convection
erf-and-erfc-functions
newton-cooling-equation
temperature-models-simple-and-convection
test-modeling-on-one-dataset
before-going-into-purrr
look-at-predictions
plot-newton-model
regular-data-frame-deltas
making-a-nested-dataframe
how-to-make-a-weird-data-frame
map-dataframes-to-a-modeling-function-newton
we-can-use-map2-to-make-the-predictions
we-need-to-get-out-of-the-weirdness
we-can-wrangle-the-predictions
we-can-visualize-the-predictions
apply-multiple-models-on-a-nested-structure
step-1-selection-of-models
step-2-write-a-function-to-define-the-inner-loop
step-3-use-map_df-to-define-the-outer-loop
step-4-use-map-to-identify-the-null-models
step-5-map_lgl-to-identify-nulls-and-get-out-of-the-weirdness
step-6-filter-nulls-and-select-variables-to-clean-up
step-7-calculate-predictions-on-nested-dataframe
unnest-make-it-tall-and-tidy
visualize-the-predictions
lets-get-the-residuals
and-visualize-them
using-broom-package-to-look-at-model-statistics
get-a-sense-of-the-coefficients
summary-1
credit-scoring-with-neuralnet
introduction-21
motivation-1
load-the-data
objective
steps
build-the-neural-network
test-the-neural-network
wine-classification-with-neuralnet
the-dataset
preprocessing
fitting-the-model-with-neuralnet
cross-validating-the-classifier
predicting-the-rating-of-cereals
introduction-22
the-basics-of-neural-networks
fitting-a-neural-network-in-r
end-notes-1
fitting-a-linear-model-with-neural-networks
introduction-23
the-dataset-1
preparing-to-fit-the-neural-network
parameters
predicting-medv-using-the-neural-network
a-fast-cross-validation
a-final-note-on-model-interpretability
visualization-of-neural-networks
caret-and-plot-nn
multiple-hidden-layers
binary-predictors
color-coding-the-input-layer
build-a-fully-connected-r-neural-network-from-scratch
introduction-24
tuning-hyperparameters-in-a-neural-network
introduction-25
replication-requirements
data-preparation
st-regression-ann
regression-hyperparameters
wrapping-up-2
deep-learning-tips-for-classification-and-regression
introduction-26
h2o-r-package
start-h2o
lets-have-some-fun-first-decision-boundaries
cover-type-dataset
first-run-of-h2o-deep-learning
variable-importances
early-stopping
adaptive-learning-rate
tuning
hyper-parameter-tuning-with-grid-search
random-hyper-parameter-search
checkpointing
cross-validation
regression-and-binary-classification
unsupervised-anomaly-detection
h2o-deep-learning-tips-tricks
performance-tuning
activation-functions
generalization-techniques
early-stopping-and-optimizing-for-lowest-validation-error
training-samples-per-mapreduce-iteration
categorical-data
sparse-data
missing-values
loss-functions-distributions-offsets-observation-weights
exporting-weights-and-biases
reproducibility
scoring-on-trainingvalidation-sets-during-training
all-done-shutdown-h2o
what-is-dot-hat-in-a-regression-output
q-q-normal-to-compare-data-to-distributions
introduction-27
why-we-want-to-compare-emprirical-vs-theoretical-distributions
the-normal-q-q-plot
drawing-a-normal-q-q-plot-from-scratch
using-rs-built-in-functions
using-the-ggplot2-plotting-environment
qq-and-pp-plots
qq-plot
some-examples
calibrating-the-variability
scalability
comparing-two-distributions
pp-plots
plots-for-assessing-model-fit
visualizing-residuals
simple-linear-regression
step-3-plot-the-actual-and-predicted-values
step-4-use-residuals-to-adjust
